{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import clear_output  # this has to be removed if used on a single script\n",
    "import random\n",
    "from preprocess import preprocess_seismo, preprocess_coord\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import GPy\n",
    "import time\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(x, y, mb_size):\n",
    "    idx = np.arange(len(x), dtype = np.int64)\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:mb_size]\n",
    "    return x[idx], y[idx], idx\n",
    "\n",
    "def plot(x, index=0):\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    plt.plot(x, label='Reconstructed')\n",
    "    plt.plot(X_data[index], label='Real')\n",
    "    plt.legend()\n",
    "\n",
    "def plot_test(x, index=0):\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    plt.plot(x, label='Reconstructed')\n",
    "    plt.plot(X_data_test[index], label='Real')\n",
    "    plt.legend()\n",
    "\n",
    "def calculate_R2(original, prediction, label, store, component=None):\n",
    "    AM = original.mean()\n",
    "    BM = prediction.mean()\n",
    "    c_vect = (original-AM)*(prediction-BM)\n",
    "    d_vect = (original-AM)**2\n",
    "    e_vect = (prediction-BM)**2\n",
    "    r_out = np.sum(c_vect)/float(np.sqrt(np.sum(d_vect)*np.sum(e_vect)))\n",
    "    if component == None:\n",
    "        print(label+str(r_out))\n",
    "    else:\n",
    "        print(str(component)+label+str(r_out))\n",
    "    store.append(r_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define number of time components in seismograms, number of coordinates, train/test split and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dim = 501 # size of the seismograms\n",
    "y_dim = 4\n",
    "# load data\n",
    "split = 2000\n",
    "test_valid = 1000\n",
    "X_data_ = np.load('./seismograms_4000seismo_ISO.npy')[:, :X_dim]\n",
    "y_data_ = np.load('./coordinates_4000seismo_ISO.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess coordinates\n",
    "y_data_preprocessed, meancoords, stdcoords = preprocess_coord(y_data_, split=split, test_valid=test_valid, sort=False, std=True)\n",
    "y_data = y_data_preprocessed[:split]\n",
    "y_data_valid =  y_data_preprocessed[split:split+test_valid]\n",
    "y_data_test =  y_data_preprocessed[split+test_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess seismograms\n",
    "X_data_preprocessed = preprocess_seismo(X_data_, split, log=False, std=False, rescale=True, rescale_onlyamp=False)\n",
    "X_data = X_data_preprocessed[:split]\n",
    "X_data_valid =  X_data_preprocessed[split:split+test_valid]\n",
    "X_data_test =  X_data_preprocessed[split+test_valid:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardise data before PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardise data to apply PCA\n",
    "meanseismo = np.mean(X_data, axis=0)\n",
    "stdseismo = np.std(X_data, axis=0)\n",
    "X_data = (X_data - meanseismo)/stdseismo\n",
    "X_data_valid = (X_data_valid - meanseismo)/stdseismo\n",
    "X_data_test = (X_data_test - meanseismo)/stdseismo\n",
    "\n",
    "selected_comp = 20\n",
    "\n",
    "pca = PCA(n_components=selected_comp)\n",
    "pca.fit(X_data)\n",
    "basis = pca.components_\n",
    "dominantseismo_train = pca.transform(X_data)\n",
    "dominantseismo_valid = pca.transform(X_data_valid)\n",
    "#dominantseismo_test = pca.transform(X_data_test)\n",
    "        \n",
    "seismo = np.matmul(dominantseismo_train, basis)\n",
    "seismo_valid = np.matmul(dominantseismo_valid, basis)\n",
    "#seismo_test = dominantseismo_test @ basis\n",
    "\n",
    "# plot training - don't think this is needed here\n",
    "#fig, ax = plt.subplots(5, figsize=(15,30))\n",
    "#for i in range(5):\n",
    "#        ax[i].plot(X_data[100*i], color='blue', label='Original')\n",
    "#        ax[i].plot(seismo[100*i], color='red', label='PCA')\n",
    "#        ax[i].set_xlabel('Time components', fontsize='x-large')\n",
    "#        ax[i].set_ylabel('Amplitude', fontsize='x-large')\n",
    "#        ax[i].set_title('Seismogram n. {:}'.format(100*i+1), fontsize='x-large')\n",
    "#        ax[i].legend(fontsize='large')\n",
    "#plt.subplots_adjust(hspace=1)\n",
    "#fig.savefig('IMAGES/PCA_rescale_{}dims_training.pdf'.format(dimension))\n",
    "#plt.show()\n",
    "#plt.close()\n",
    "\n",
    "# R2\n",
    "#AM = X_data.mean()\n",
    "#BM = seismo.mean()\n",
    "#c_vect = (X_data-AM)*(seismo-BM)\n",
    "#d_vect = (X_data-AM)**2\n",
    "#e_vect = (seismo-BM)**2\n",
    "#r_out = np.sum(c_vect)/float(np.sqrt(np.sum(d_vect)*np.sum(e_vect)))\n",
    "#np.savetxt('R2/r2_PCA_rescale_{}dims_training.txt'.format(dimension), r_out[None])\n",
    "#print(r_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_GP = np.zeros((test_valid, selected_comp))\n",
    "# fit a GP to the components\n",
    "for component in range(selected_comp):\n",
    "    ker = GPy.kern.Matern32(4,ARD=True)\n",
    "    m = GPy.models.GPRegression(y_data, dominantseismo_train[:, component].reshape(-1, 1), ker)\n",
    "    m.optimize(messages=True,max_f_eval = 1000)\n",
    "\n",
    "    y_pred_train = m.predict(y_data)[0]\n",
    "    y_pred_train = y_pred_train[:, 0]\n",
    "    calculate_R2(dominantseismo_train[:, component], y_pred_train, ' component R2 training: ', [], component)\n",
    "\n",
    "    y_pred_valid = m.predict(y_data_valid)[0]\n",
    "    y_pred_valid = y_pred_valid[:, 0]\n",
    "    calculate_R2(dominantseismo_valid[:, component], y_pred_valid, ' component R2 validation: ', [], component)\n",
    "\n",
    "    y_pred_test = m.predict(y_data_test)[0]\n",
    "    fitted_GP[:, component] = y_pred_test[:, 0]\n",
    "\n",
    "    np.save(f'./saved_models_iso_PCAplusGP/GPmodel_{component}.npy', m.param_array)\n",
    "    #plt.plot(shift_index_test, color='blue')\n",
    "    #plt.show()\n",
    "    #plt.plot(y_pred_test_2, color='red')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP training for Amplitude and Time shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_rescale = np.loadtxt('./amplitude_rescale_NOTsorted.txt')\n",
    "shift_index = np.loadtxt('./shift_index_NOTsorted.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_rescale_train = amplitude_rescale[:split].reshape(X_data.shape[0], 1)\n",
    "amplitude_rescale_valid = amplitude_rescale[split:split+test_valid]\n",
    "amplitude_rescale_test = amplitude_rescale[split+test_valid:]\n",
    "\n",
    "shift_index_train = shift_index[:split].reshape(X_data.shape[0], 1)\n",
    "shift_index_valid = shift_index[split:split+test_valid]\n",
    "shift_index_test = shift_index[split+test_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit GP to data rescaling\n",
    "# amplitude\n",
    "kern = GPy.kern.Matern32(4,ARD=True)\n",
    "n = GPy.models.GPRegression(y_data, amplitude_rescale_train, kern)\n",
    "n.optimize(messages=True, max_f_eval = 1000)\n",
    "\n",
    "y_pred_train = n.predict(y_data)[0]\n",
    "y_pred_train = y_pred_train[:, 0]\n",
    "calculate_R2(amplitude_rescale_train.flatten(), y_pred_train, 'Amplitude R2 train: ', [])\n",
    "\n",
    "y_pred_valid = n.predict(y_data_valid)[0]\n",
    "y_pred_valid = y_pred_valid[:, 0]\n",
    "calculate_R2(amplitude_rescale_valid, y_pred_valid, 'Amplitude R2 validation: ', [])\n",
    "\n",
    "# this is to be used later\n",
    "y_pred_test = n.predict(y_data_test)[0]\n",
    "y_pred_test = y_pred_test[:, 0]\n",
    "\n",
    "#plt.plot(amplitude_rescale_test, color='blue')\n",
    "#plt.show()\n",
    "#plt.plot(y_pred_test, color='red')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time shift\n",
    "ker = GPy.kern.Matern32(4,ARD=True)\n",
    "m = GPy.models.GPRegression(y_data,shift_index_train,ker)\n",
    "m.optimize(messages=True,max_f_eval = 1000)\n",
    "\n",
    "y_pred_train_2 = m.predict(y_data)[0]\n",
    "y_pred_train_2 = y_pred_train_2[:, 0]\n",
    "calculate_R2(shift_index_train.flatten(), y_pred_train_2, 'Time shift R2 training: ', [])\n",
    "\n",
    "y_pred_valid_2 = m.predict(y_data_valid)[0]\n",
    "y_pred_valid_2 = y_pred_valid_2[:, 0]\n",
    "calculate_R2(shift_index_valid, y_pred_valid_2, 'Time shift R2 validation: ', [])\n",
    "\n",
    "y_pred_test_2 = m.predict(y_data_test)[0]\n",
    "y_pred_test_2 = y_pred_test_2[:, 0]\n",
    "\n",
    "#plt.plot(shift_index_test, color='blue')\n",
    "#plt.show()\n",
    "#plt.plot(y_pred_test_2, color='red')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain reconstructed seismo for the test set\n",
    "prediction_testing = fitted_GP@basis\n",
    "\n",
    "prediction_testing = prediction_testing*stdseismo+meanseismo\n",
    "\n",
    "prediction_testing = np.multiply(prediction_testing, np.repeat(1/y_pred_test, X_dim).reshape(-1, X_dim))\n",
    "for index_seism in range(test_valid):\n",
    "    prediction_testing[index_seism] = shift(prediction_testing[index_seism], -y_pred_test_2[index_seism], cval=0.)\n",
    "\n",
    "# retrieve the unprocessed data back\n",
    "X_data_preprocessed = preprocess_seismo(X_data_, split, log=False, std=False, rescale=False, rescale_onlyamp=False)\n",
    "X_data_test = X_data_preprocessed[split+test_valid:]\n",
    "\n",
    "calculate_R2(X_data_test, prediction_testing, 'Final R2 testing: ', [])\n",
    "\n",
    "#for i in range(5):\n",
    "#    plt.plot(X_data_test[i], color='blue')\n",
    "#    plt.plot(prediction_testing[i], color='red')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total time, to be quoted in the paper\n",
    "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_GP = []\n",
    "# fit a GP to the components\n",
    "for component in range(selected_comp):\n",
    "    ker = GPy.kern.Matern32(4,ARD=True)\n",
    "    m = GPy.models.GPRegression(y_data, dominantseismo_train[:, component].reshape(-1, 1), ker)\n",
    "    m.update_model(False) # do not call the underlying expensive algebra on load\n",
    "    m.initialize_parameter() # Initialize the parameters (connect the parameters up)\n",
    "    m[:] = np.load('./saved_models_iso_PCAplusGP/GPmodel_{}.npy'.format(component)) # Load the parameters\n",
    "    m.update_model(True) # do not call the underlying expensive algebra on load\n",
    "    fitted_GP.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker = GPy.kern.Matern32(4,ARD=True) \n",
    "m_load = GPy.models.GPRegression(y_data, amplitude_rescale_train, ker, initialize=False)\n",
    "m_load.update_model(False) # do not call the underlying expensive algebra on load\n",
    "m_load.initialize_parameter() # Initialize the parameters (connect the parameters up)\n",
    "m_load[:] = np.load('./saved_models_iso_PCAplusGP/GPmodel_amplitude.npy') # Load the parameters\n",
    "m_load.update_model(True) # Call the algebra only once\n",
    "\n",
    "kern = GPy.kern.Matern32(4,ARD=True) \n",
    "n_load = GPy.models.GPRegression(y_data, shift_index_train, kern, initialize=False)\n",
    "n_load.update_model(False) # do not call the underlying expensive algebra on load\n",
    "n_load.initialize_parameter() # Initialize the parameters (connect the parameters up)\n",
    "n_load[:] = np.load('./saved_models_iso_PCAplusGP/GPmodel_time.npy') # Load the parameters\n",
    "n_load.update_model(True) # Call the algebra only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_inference = time.time()\n",
    "\n",
    "coordinate = np.array([31,25,158])\n",
    "\n",
    "shifted = coordinate - np.array([41,41,244])\n",
    "distances = np.linalg.norm(shifted)\n",
    "new_coords = np.zeros(4)\n",
    "new_coords[:3] = shifted\n",
    "new_coords[-1] = distances\n",
    "new_coords = (new_coords - meancoords)/stdcoords\n",
    "new_coords = new_coords.reshape((1,y_dim))\n",
    "\n",
    "predPCA = np.zeros(selected_comp)\n",
    "for i in range(selected_comp):\n",
    "    predPCA_tmp = fitted_GP[i].predict(new_coords)[0]\n",
    "    predPCA[i] = predPCA_tmp[:, 0]\n",
    "prediction_testing = np.matmul(predPCA, basis)\n",
    "prediction_testing = prediction_testing*stdseismo+meanseismo\n",
    "y_pred_test = m_load.predict(new_coords)[0]\n",
    "y_pred_test = y_pred_test[:, 0]\n",
    "y_pred_test_2 = n_load.predict(new_coords)[0]\n",
    "y_pred_test_2 = y_pred_test_2[:, 0]\n",
    "prediction_testing = np.multiply(prediction_testing, np.repeat(1/y_pred_test, X_dim).reshape(-1, X_dim))\n",
    "prediction_testing = shift(prediction_testing[0], -y_pred_test_2, cval=0.)\n",
    "\n",
    "timeinf = time.time() - start_time_inference\n",
    "print(\"timeinf\", timeinf)\n",
    "np.save(\"PCA_plus_GP_inftime.npy\", timeinf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
